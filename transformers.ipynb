{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers demo",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-tomas/workshops/blob/main/transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXfL5fF23n_7"
      },
      "source": [
        "# Intro\n",
        "\n",
        "ü§ó [Transformers](https://huggingface.co/transformers/) library provides general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet...) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with deep interoperability between Jax, PyTorch and TensorFlow.\n",
        "\n",
        "There are more than 30,000 pre-trained [models](https://huggingface.co/models) and 2,000 [datasets](https://huggingface.co/datasets) available in their web page, covering tenths of different tasks in more than 100 languages.\n",
        "\n",
        "This demo exemplifies the use of [pipelines](https://huggingface.co/transformers/main_classes/pipelines.html). These pipelines are objects that abstract most of the complex code from the library, offering a simple API dedicated to several tasks, including Named Entity Recognition, Masked Language Modeling, Sentiment Analysis, and Question Answering.\n",
        "\n",
        "The following examples are inspired in the ü§ó Transformers library [course](https://huggingface.co/course/chapter1/3?fw=pt)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHMnv2E342Fm"
      },
      "source": [
        "#Initial setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV_HYIqh5CE3"
      },
      "source": [
        "# Install the Transformers library\n",
        "!pip install transformers[sentencepiece]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NSb5zwW5A4N"
      },
      "source": [
        "# Import the required libraries\n",
        "from transformers import pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PGM6PKs5Snr"
      },
      "source": [
        "# Sentiment analysis\n",
        "Classify a sentence according to positive or negative sentiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX5WMJdU3oAA"
      },
      "source": [
        "# Load the sentiment analysis model ('distilbert-base-uncased-finetuned-sst-2-english' by default)\n",
        "model = pipeline('sentiment-analysis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlrPG-1D_FpG"
      },
      "source": [
        "# Try it!\n",
        "model('This is the best keynote speech I have ever attended in my life. Praise to David!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prxs4c3n5maC"
      },
      "source": [
        "# Zero-shot classification\n",
        "Classify text according to a set of given labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4VmJfFP3oAD"
      },
      "source": [
        "# Load the zero-shot classification model ('facebook/bart-large-mnli' by default)\n",
        "model = pipeline('zero-shot-classification')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTVpFRiJ_dfC"
      },
      "source": [
        "# Try it!\n",
        "model('This lecture is about Natural Language Processing', candidate_labels=['education', 'politics', 'business', 'sports'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c9SSfQ15qOR"
      },
      "source": [
        "# Text generation\n",
        "Predict the words that will follow a specified text prompt, creating a coherent portion of text that is a continuation from the given context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sF7nvV53oAE"
      },
      "source": [
        "# Load the text generation model ('gpt2' by default)\n",
        "model = pipeline('text-generation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R-Ug0w9_3Gr"
      },
      "source": [
        "# Try it! (you will get a different output each time)\n",
        "model('I opened the door and found')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjK_vuMJLnjd"
      },
      "source": [
        "# Tyr it tuning some parameters (maximum length generated and number of returned sentences)!\n",
        "model('The book was amazing', max_length=40, num_return_sequences=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMCMRci-50EQ"
      },
      "source": [
        "# Masked language modelling\n",
        "Mask a token in a sequence with a masking token, and prompt the model to fill that mask with an appropriate token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkfgWn9w3oAG"
      },
      "source": [
        "# Load the masked language modelling model ('distilroberta-base' by default)\n",
        "model = pipeline('fill-mask')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0i8Z800HBNf"
      },
      "source": [
        "# Try it (returning the 'top_k' words)!\n",
        "model('I <mask> this lecture.', top_k=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10ng8r4o56fn"
      },
      "source": [
        "# Named entity recognition\n",
        "Classify tokens according to a class (e.g. person, organisation or location)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhPIxSHb3oAH"
      },
      "source": [
        "# Load the named entity recognition model ('dbmdz/bert-large-cased-finetuned-conll03-english' by default)\n",
        "model = pipeline('ner', grouped_entities=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6VpnMVdHFCe"
      },
      "source": [
        "# Try it!\n",
        "model('My name is David and I live in Spain.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3sWhD7T6BBp"
      },
      "source": [
        "# Question answering\n",
        "Extract an answer from a text given a question."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Xru5M-3oAI"
      },
      "source": [
        "# Load the question answering model ('distilbert-base-cased-distilled-squad' by default)\n",
        "model = pipeline('question-answering')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5yQynCSHKJL"
      },
      "source": [
        "# Try it!\n",
        "model(question='Where do I work?', context='My name is David and I work really hard at the Unviersity of Alicante')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArXQ5bVg6J6n"
      },
      "source": [
        "# Machine translation\n",
        "Translate from one language to another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qclfzyE3oAJ"
      },
      "source": [
        "# Load the machine translation model from ES to EN ('Helsinki-NLP/opus-mt-es-en')\n",
        "# Try different models changing 'Helsinki-NLP/opus-mt-{src}-{tgt}' (src = source language, tgt = target)\n",
        "model = pipeline('translation', model='Helsinki-NLP/opus-mt-es-en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbqOL0RIHUkD"
      },
      "source": [
        "# Try it!\n",
        "model('Ojal√° el pr√≥ximo a√±o pueda ir a Alicante')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}